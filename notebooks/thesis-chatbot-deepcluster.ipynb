{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"params = {\n    'num_clusters': 50,\n    'num_components': 256,\n    'image_size': (384, 380),\n    'random_state': 123,\n\n    'lr': 1e-4,\n    'max_lr': 1e-4,\n    'epochs': 100,\n    'batch_size': 16,\n    'print_interval': 0.3,\n    \n    'save_path': 'CNN-k50.pt',\n    'use_pretrained': True,\n\n    'wandb_key': '6f927fe3835ebcc7bb05946984340ac2c810388e',\n    'wandb_run_name': 'Run 1 (k = 50, b4, pretrained)'\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-05T15:18:28.382645Z","iopub.execute_input":"2022-04-05T15:18:28.383217Z","iopub.status.idle":"2022-04-05T15:18:28.419413Z","shell.execute_reply.started":"2022-04-05T15:18:28.383125Z","shell.execute_reply":"2022-04-05T15:18:28.418528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q --upgrade torchvision\n!pip install -q --upgrade datasets","metadata":{"execution":{"iopub.status.busy":"2022-04-05T15:18:36.129425Z","iopub.execute_input":"2022-04-05T15:18:36.129693Z","iopub.status.idle":"2022-04-05T15:20:17.333151Z","shell.execute_reply.started":"2022-04-05T15:18:36.129663Z","shell.execute_reply":"2022-04-05T15:20:17.332127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:03:55.322749Z","iopub.execute_input":"2022-04-05T08:03:55.322999Z","iopub.status.idle":"2022-04-05T08:03:55.327308Z","shell.execute_reply.started":"2022-04-05T08:03:55.32296Z","shell.execute_reply":"2022-04-05T08:03:55.325979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yaml\nimport torch\nimport torchvision\nfrom torch import optim, nn\nfrom torchvision import models, transforms\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport cv2\nfrom PIL import Image\nimport os\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nimport plotly.express as px\nfrom datasets import Dataset\nimport datasets\nfrom sklearn.decomposition import PCA\nimport wandb\nimport os\nfrom sklearn.metrics.cluster import normalized_mutual_info_score\nfrom sklearn.metrics import average_precision_score\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader,Dataset\nfrom sklearn.metrics import f1_score\n# datasets.disable_progress_bar()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T15:20:37.939368Z","iopub.execute_input":"2022-04-05T15:20:37.939682Z","iopub.status.idle":"2022-04-05T15:20:44.48987Z","shell.execute_reply.started":"2022-04-05T15:20:37.939652Z","shell.execute_reply":"2022-04-05T15:20:44.488792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_config(path = 'config.yml'):\n    with open('../input/thesis-chatbot/' + path) as f:\n        config =  yaml.safe_load(f)\n    return config\n\ndef get_train_imgs(img_ls):\n    \"\"\"\n    Lấy ảnh ở tập train ra, kiểm tra xác thực đảm bảo \n    nó có trong folder chứa ảnh\n        \n        Params:\n            img_ls (pandas series): danh sách ảnh train/val\n\n        Returns: \n            temp (list): danh sách ảnh output\n    \"\"\"\n    img_train = img_ls.dropna().values\n    img_train = list(set(img_train))\n\n    img_folder = os.listdir('../input/thesis-chatbot/' + config['path']['image_path'])\n\n    temp = []\n    for img in img_train:\n        if img in img_folder:\n            temp.append(img)\n    \n    return temp\n\n\ndef feed_img(model, img_file, image_size):\n    \"\"\"\n    Đưa 1 ảnh qua mô hình\n        Params: \n            model (pytorch module): mô hình\n            img_file (str): tên file ảnh\n            image_size (int, int): kích thước ảnh sau khi resize cho input mô hình\n            \n    \"\"\"\n    device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    filename = '../input/thesis-chatbot/' + str(config['path']['image_path']) + str(img_file)\n    # try:\n    img_file = Image.open(str(filename))\n    \n    # Gif \n    img_file = np.array(img_file.convert('RGB'))\n  \n    # Return None nếu file ảnh không đọc được\n    if img_file is None:\n        #Dùng None thay vì continue, continue thì xuống dưới hong bỏ được tên ảnh mà feature nó bị None\n        #check if feature not None, mới cho lấy tên ảnh, feature --> làm luôn 2 việc.\n        return None  \n\n    # Transform the image\n    transform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.CenterCrop(512),\n        transforms.Resize(image_size),\n        transforms.ToTensor()                              \n    ])\n\n    img_file = transform(img_file)\n\n    # Reshape the image. PyTorch model reads 4-dimensional tensor\n    # [batch_size, channels, width, height]\n    img_file = img_file.reshape(1, 3, image_size[0], image_size[1])\n    img_file = img_file.to(device)\n    # We only extract features, so we don't need gradient\n    \n    with torch.no_grad():\n        model.eval()\n    # Extract the feature from the image\n        feature = model(img_file)\n    # Convert to NumPy Array, Reshape it, and save it to features variable\n    return feature.cpu().detach().numpy().reshape(-1)\n\ndef feed_single_img(model, example):\n    \"\"\"\n    Mỗi step sẽ làm gì - feed ảnh qua mô hình\n    Feature được lưu ở cột features\n        Params:\n            model (Pytorch module): mô hình CNN\n            example: 1 dòng trong dataframe\n        Returns:\n            example: 1 dòng trong dataframe (đã thêm cột features)\n    \"\"\"\n    example['features'] = feed_img(model, example['img'], params['image_size'])\n    return example\n\ndef get_img_features_faster(img_train):\n    \"\"\"\n    Đưa toàn bộ ảnh qua mô hình - xử lí song song\n    Tên ảnh được lưu ở cột 'img'\n    Feature được lưu ở cột 'features'\n        Params:\n            model (pytorch module): mô hình CNN ở biến global\n            img_train (list): danh sách tên ảnh train\n        Returns:\n            temp (huggingface dataset): class dataset của huggingface\n                    Giống dictionary\n    \"\"\"\n    global model\n    temp = pd.DataFrame({'img': img_train})\n    temp = datasets.Dataset.from_pandas(temp)\n    temp = temp.map(lambda x: feed_single_img(model, x))\n    return temp\n\ndef kmean_fit(features, n_clusters, random_state = 42):\n    \"\"\"\n    Run kmean clustering\n        Params:\n            features (list): list các features ảnh trong tập train\n            n_clusters: số cluster\n            random_state: fixed random state\n        \n        Returns:\n            labels (list): list nhãn giả tương ứng với features\n    \"\"\"\n    # Initialize the model\n    kmean_model = KMeans(n_clusters=n_clusters, random_state=random_state)\n    # Fit the data into the model\n    kmean_model.fit(features)\n    # Extract the labels\n    labels = kmean_model.labels_\n    return labels\n\ndef make_pseudo_labels(img_train, num_components, num_clusters):\n    # Feed lấy image features\n    img_dataset = get_img_features_faster(img_train)\n\n    # PCA rút gọn features\n    pca = PCA(n_components= num_components, random_state= params['random_state'])\n    pca_data = pca.fit_transform(img_dataset['features'])\n\n    # Kmean clustering\n    labels = kmean_fit(pca_data, n_clusters = num_clusters, random_state = params['random_state'])\n    return labels, img_dataset\n\nclass MyData(Dataset):\n\n    def __init__(self, img_dataset, labels, transform):\n        self.img_dataset = img_dataset\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(img_dataset)\n\n    def __getitem__(self, index):\n        image = Image.open('../input/thesis-chatbot/' + config['path']['image_path'] + img_dataset['img'][index])\n        image = np.array(image.convert('RGB'))\n\n        if self.transform is not None:\n            image = self.transform(image)\n        labels = self.labels[index]\n\n        return {'images': image, 'labels': labels}\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n        \n    def forward(self, x):\n        return x\ndef remove_classifier(model):\n    \"\"\"\n    Tháo lớp classifier ra khỏi mô hình \n        Params:\n            model (pytorch_module): mô hình\n                pass by reference, thay đổi sẽ ảnh hưởng thẳng tới biến mô hình\n                !!! classifier sẽ là attribute model.classifier\n                --> mình đè lên bằng class Identity - class fake lấy output là ouput của lớp trước nó\n        Returns:\n            None\n    \"\"\"\n\n    # Class Identity: class fake không có gì ở trong, \n    # lấy output của lớp trước đó output ra luôn\n\n\n    model.classifier[1] = Identity()\n\ndef add_classifier(model, last_layer_shape: int, num_classes: int):\n    \"\"\"\n    Gắn lớp classifier vào mô hình\n        Params:\n            model (pytorch module): mô hình\n                pass by reference, thay đổi sẽ ảnh hưởng thẳng tới biến\n                !!! module mô hình có attribute model.classifier, \n               \n            last_layer_shape (int): kích thước đầu ra của layer trước đó \n                    (image representation layer)\n\n            num_classes (int): số class đầu ra cho classification\n    \"\"\"\n\n    model.classifier[1] = nn.Linear(last_layer_shape, num_classes)\n    \n\n# METRIC----------------------\ndef accuracy(predictions, labels):\n    classes = torch.argmax(predictions, dim=1)\n    return torch.mean((classes == labels).float())\n\ndef nmi(predictions, labels, is_prob = True):\n    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html\n    if is_prob:\n        classes = torch.argmax(predictions, dim=1)\n    else:\n        classes = predictions\n    return normalized_mutual_info_score(classes, labels)\n\ndef f1(predictions, labels):\n    classes = torch.argmax(predictions, dim=1)\n    return f1_score(labels, classes, average='weighted')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T15:20:44.49512Z","iopub.execute_input":"2022-04-05T15:20:44.495377Z","iopub.status.idle":"2022-04-05T15:20:44.535323Z","shell.execute_reply.started":"2022-04-05T15:20:44.495341Z","shell.execute_reply":"2022-04-05T15:20:44.534315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load config\nconfig = read_config()\n# Load df\ndf = pd.read_pickle('../input/thesis-chatbot/' + config['path']['train_preprocessed_path'])\n# Get list of train imgs\nimg_train = get_train_imgs(df['img_id'])\n# Load model\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n\n# Update model\nif params['use_pretrained']:\n    model = models.efficientnet_b4(pretrained=True)\nelse:\n    model = models.efficientnet_b4()\n# Kích thước của lớp biểu diễn đặc trưng ảnh\n# b4: 1408, b0: 1280 tuỳ version của model. Mình set bằng biến cho linh hoạt\nprojection_shape = model.classifier[1].in_features  \nmodel.classifier = nn.Sequential(\n                                nn.Linear(projection_shape, 768),\n                                nn.Linear(768, params['num_clusters'])\n                                )\n\n#Transform tăng cường ảnh \ntransform_aug = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.CenterCrop(512),\n                transforms.Resize(params['image_size']),\n                transforms.RandomChoice([ # random 1 phép để dùng\n                    transforms.RandomHorizontalFlip(p=0.5), #lật ngang\n                    transforms.RandomRotation(degrees=30),  #xoay góc 30\n                    # thay đổi độ sáng, tương phản, bão hoà, hue\n                    transforms.ColorJitter(brightness= (0.1, 1), contrast= (0.1, 1), saturation= (0.1, 1), hue= (-0.1, 0.1)),\n                    transforms.RandomPerspective(), #quay góc nhìn\n                ]),\n                transforms.ToTensor()])\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr= params['lr'])\n# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                                # max_lr= params['max_lr'], \n                                                # steps_per_epoch=len(train_loader), \n                                                # epochs= params['epochs'])\n\nos.environ[\"WANDB_API_KEY\"] = params['wandb_key']\nwandb.init(config = params, project=\"CNN brrr\", entity=\"thesis-chatbot\", name = params['wandb_run_name'])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T15:20:46.95945Z","iopub.execute_input":"2022-04-05T15:20:46.95977Z","iopub.status.idle":"2022-04-05T15:21:02.031438Z","shell.execute_reply.started":"2022-04-05T15:20:46.959716Z","shell.execute_reply":"2022-04-05T15:21:02.030383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(1, params['epochs'] + 1)):\n    print(f\"\\n\\nEpoch {epoch}\")\n    print(\"=\" * 10)\n\n    # 1. Remove classifier\n    img_train = get_train_imgs(df['img_id'])\n    remove_classifier(model)\n\n    # 2. Clustering\n    print(\"Clustering...\")\n    model.eval() #bật chế độ inference (tắt dropout)\n    \n    # Nếu epoch > 1, Tính NMI giữa pseudo labels của epoch hiện tại vs pseudo labels của epoch trước đó\n    if epoch > 1:\n        previous_labels = labels\n        labels, img_dataset = make_pseudo_labels(img_train, \n               num_components = params['num_components'],\n               num_clusters = params['num_clusters'])\n        reassign_nmi = nmi(labels, previous_labels, is_prob = False)\n        print(f\"Reassigned NMI: {reassign_nmi}\")\n        wandb.log({'Reassigned NMI': reassign_nmi})\n        \n    else:\n        labels, img_dataset = make_pseudo_labels(img_train, \n                   num_components = params['num_components'],\n                   num_clusters = params['num_clusters'])\n\n\n    # 3. Dataset + Dataloader\n    train_set = MyData(img_dataset, labels, transform_aug)\n    train_loader = torch.utils.data.DataLoader(train_set, \n                            batch_size=params['batch_size'], \n                            shuffle=True)\n\n    # 4. Add classifier\n    add_classifier(model, 768, params['num_clusters'])\n    model = model.to(device) # đưa dô gpu (nếu có)\n\n    # 5. Classification\n    print(\"Training...\")\n    running_loss = []\n    running_accuracy = []\n    running_nmi = []\n    running_f1 = []\n    \n\n    for i, data in enumerate(tqdm(train_loader)):\n        model.train()\n        inputs, labels_int = data['images'].to(device), data['labels'].to(device)  \n\n        # reset gradients đã tính mỗi batch\n        optimizer.zero_grad()\n        \n        # forward \n        outputs = model(inputs)\n        long_labels = labels_int.type(torch.LongTensor).to(device)\n\n        # Loss\n        loss = criterion(outputs, long_labels)\n\n        # backward\n        loss.backward()\n\n        # Gradient clipping - prevent exploding gradient\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm= 1.0)\n\n        # Update weights\n        optimizer.step()\n\n        # Đưa loss, accuracy\n        running_loss.append(loss.item())\n        running_accuracy.append(accuracy(outputs, long_labels))\n\n        # Hàm nmi cần nhận vào các biến ở cpu\n        running_nmi.append(nmi(outputs.detach().cpu(), long_labels.detach().cpu(), is_prob = True))\n        running_f1.append(f1(outputs.detach().cpu(), long_labels.detach().cpu()))\n    \n    \n    # Do train 1 epoch quá lẹ nên chỉ cần lấy metric cuối epoch\n    # Loss\n    last_loss = torch.mean(torch.Tensor(running_loss))\n    # Accuracy\n    last_accuracy = torch.mean(torch.Tensor(running_accuracy))\n    # Pred NMI\n    last_nmi = torch.mean(torch.Tensor(running_nmi))\n    # f1\n    last_f1 = torch.mean(torch.Tensor(running_f1))\n\n    # In ra\n    print(f\"Epoch {epoch} ({i + 1}/{len(train_loader)}), Loss: {last_loss:.3f}, Accuracy: {last_accuracy:.3f}, Pred NMI: {last_nmi:.3f}, F1: {last_f1:.3f}\")\n\n    # Log qua wandb, 4 plots\n    wandb.log({\"train/loss\": last_loss, \n                'train/accuracy': last_accuracy,\n                'train/Pred NMI': last_nmi,\n                'train/f1': last_f1})\n    \n    # Luu\n    torch.save(model.state_dict(), params['save_path'])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:44:26.596762Z","iopub.execute_input":"2022-04-05T08:44:26.59709Z","iopub.status.idle":"2022-04-05T09:39:47.454795Z","shell.execute_reply.started":"2022-04-05T08:44:26.597055Z","shell.execute_reply":"2022-04-05T09:39:47.453884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}